{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b0a4388",
   "metadata": {},
   "source": [
    "Using jupyter and an cloud scheduler to scrape AI news from news sites using news API. This then send me the news in a csv to my email weekly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68da1ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Installing and running necessary libraries\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import requests\n",
    "import pandas as pd\n",
    "import smtplib\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email.mime.base import MIMEBase\n",
    "from email.mime.text import MIMEText\n",
    "from email import encoders\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25a1fb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#configuration\n",
    "API_KEY = \"80e9d4f5c07e4882a64c64c9cc472460\" \n",
    "EMAIL_SENDER = \"muterujecinta@gmail.com\"  \n",
    "EMAIL_PASSWORD = \"livebig20\"  \n",
    "EMAIL_RECEIVER = \"muterujecinta@gmail.com\" \n",
    "CSV_FILE = \"ai_data_news.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c322f5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetch news from news API\n",
    "def fetch_news():\n",
    "    url = \"https://newsapi.org/v2/everything\"\n",
    "    from_date = (datetime.now() - timedelta(days=7)).strftime('%Y-%m-%d')\n",
    "    params = {\n",
    "        \"q\": \"artificial intelligence OR data science OR data analytics OR data jobs OR machine learning OR LLM OR large language models\",\n",
    "        \"from\": from_date,\n",
    "        \"sortBy\": \"publishedAt\",\n",
    "        \"language\": \"en\",\n",
    "        \"apiKey\": API_KEY\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, params=params, timeout=10)\n",
    "        response.raise_for_status()  # Raise exception for bad status codes\n",
    "        data = response.json()\n",
    "        return data.get(\"articles\", [])\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error fetching news: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2274c849",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load existing links for deduplication\n",
    "def load_existing_links():\n",
    "    if os.path.exists(CSV_FILE):\n",
    "        try:\n",
    "            df = pd.read_csv(CSV_FILE)\n",
    "            return set(df[\"Link\"].dropna().tolist())\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading CSV: {e}\")\n",
    "    return set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "edb36170",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the news article to the csv file\n",
    "def save_to_csv(articles, existing_links):\n",
    "    if not articles:\n",
    "        return 0\n",
    "    rows = []\n",
    "    scraped_date = datetime.now().strftime('%Y-%m-%d')\n",
    "    \n",
    "    for article in articles:\n",
    "        link = article.get(\"url\", \"N/A\")\n",
    "        if link in existing_links:\n",
    "            continue\n",
    "        description = article.get(\"description\", \"N/A\")\n",
    "        if description is None:  # Handle null description\n",
    "            description = \"N/A\"\n",
    "        row = {\n",
    "            \"Scraped Date\": scraped_date,\n",
    "            \"Title\": article.get(\"title\", \"N/A\"),\n",
    "            \"Link\": link,\n",
    "            \"Pub Date\": article.get(\"publishedAt\", \"N/A\").split(\"T\")[0],\n",
    "            \"Source\": article.get(\"source\", {}).get(\"name\", \"N/A\"),\n",
    "            \"Description\": description[:500]  # Truncate for brevity\n",
    "        }\n",
    "        rows.append(row)\n",
    "    \n",
    "    if rows:\n",
    "        df = pd.DataFrame(rows)\n",
    "        df.to_csv(CSV_FILE, mode='a', index=False, header=not os.path.exists(CSV_FILE), encoding='utf-8')\n",
    "    return len(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "79e086e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Send CSV via email\n",
    "def send_email(num_articles):\n",
    "    if not os.path.exists(CSV_FILE):\n",
    "        print(\"No CSV file to send.\")\n",
    "        return\n",
    "    \n",
    "    msg = MIMEMultipart()\n",
    "    msg['From'] = EMAIL_SENDER\n",
    "    msg['To'] = EMAIL_RECEIVER\n",
    "    msg['Subject'] = \"Weekly AI/Data News Summary CSV\"\n",
    "    body = f\"Attached is the CSV with {num_articles} new articles on AI, data science, analytics, and jobs from the past week.\"\n",
    "    msg.attach(MIMEText(body, 'plain'))\n",
    "    \n",
    "    with open(CSV_FILE, 'rb') as f:\n",
    "        part = MIMEBase('application', 'octet-stream')\n",
    "        part.set_payload(f.read())\n",
    "    encoders.encode_base64(part)\n",
    "    part.add_header('Content-Disposition', f'attachment; filename={CSV_FILE}')\n",
    "    msg.attach(part)\n",
    "    \n",
    "    try:\n",
    "        server = smtplib.SMTP('smtp.gmail.com', 587)  # Adjust for your email provider\n",
    "        server.starttls()\n",
    "        server.login(EMAIL_SENDER, EMAIL_PASSWORD)\n",
    "        server.sendmail(EMAIL_SENDER, EMAIL_RECEIVER, msg.as_string())\n",
    "        server.quit()\n",
    "        print(f\"Email sent with {num_articles} articles.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error sending email: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa5053fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No new articles to save or send.\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    articles = fetch_news()\n",
    "    if not articles:\n",
    "        print(\"No new AI/data news found this week.\")\n",
    "        return\n",
    "    \n",
    "    existing_links = load_existing_links()\n",
    "    num_articles = save_to_csv(articles, existing_links)\n",
    "    \n",
    "    if num_articles > 0:\n",
    "        send_email(num_articles)\n",
    "    else:\n",
    "        print(\"No new articles to save or send.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
